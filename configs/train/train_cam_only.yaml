# model name
exp_name: 'CAM_ONLY'

# Training parameters
max_iters: 75000
log_freq: 100
shuffle: true
dset: 'trainval'
save_freq: 1000
batch_size: 1
grad_acc: 5
lr: 0.0003
use_scheduler: true
weight_decay: 0.0000001
nworkers: 4

# Directories
data_dir: '/datasets/nuscenes'
custom_dataroot: 'datasets/scaled_images'
log_dir: 'logs_nuscenes'
ckpt_dir: 'model_checkpoints'
keep_latest: 75
init_dir: ''
ignore_load: null
load_step: true
load_optimizer: true
load_scheduler: true

# Data parameters
final_dim: [448, 896]  # to match //8, //14, //16 and //32 in Vit
rand_flip: true
rand_crop_and_resize: true
ncams: 6
nsweeps: 5

# Model parameters
encoder_type: 'dino_v2'
radar_encoder_type: null
use_rpn_radar: false
train_task: 'both'
use_radar: false
use_radar_filters: false
use_radar_encoder: false
use_metaradar: false
use_shallow_metadata: false
use_pre_scaled_imgs: false
use_obj_layer_only_on_map: true
init_query_with_image_feats: true
do_rgbcompress: true
do_shuffle_cams: true
use_multi_scale_img_feats: true
num_layers: 6

device_ids: [0,1,2,3,4,5,6,7]
freeze_dino: true
do_feat_enc_dec: true
combine_feat_init_w_learned_q: true
model_type: 'transformer'
use_radar_occupancy_map: false
learnable_fuse_query: true

# wandb
group: 'CAM_ONLY'
notes: 'BEVCar model but without the radar data and thus no fusion transformer stage'
name: 'CAM_ONLY'
